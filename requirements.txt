fastapi==0.104.1
uvicorn==0.24.0
pydantic==2.4.2
requests==2.31.0
streamlit==1.28.1
python-jose==3.3.0
web3==6.11.1
python-multipart==0.0.6
python-dotenv==1.0.0
cryptography==41.0.7
google-generativeai==0.3.2
python-dotenv
# For local Llama model support
transformers>=4.35.0
torch>=2.0.0
accelerate>=0.20.0
sentencepiece
protobuf

# Optional: For better GPU support
# bitsandbytes  # For 8-bit quantization
# flash-attn    # For faster attention (requires CUDA)